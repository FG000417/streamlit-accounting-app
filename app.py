import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import KNeighborsClassifier
from collections import Counter 
import jieba
import sys
import os # ç”¨æ–¼æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨

# --- æ­¥é©Ÿé›¶ï¼šé…ç½®èˆ‡æ•¸æ“šæº–å‚™ ---

# ğŸš¨ è«‹å°‡ 'filename.xlsx' æ›¿æ›æˆæ‚¨çš„å¯¦éš›æª”æ¡ˆè·¯å¾‘èˆ‡åç¨±
DATA_FILE = r'æœƒè¨ˆæ­·å²è³‡æ–™.xlsx' 

# ğŸš¨ é…ç½® K-è¿‘é„°çš„ K å€¼ (å¯ä»¥èª¿æ•´ï¼Œé€šå¸¸æ˜¯ 3 æˆ– 5)
N_NEIGHBORS = 5

# ğŸš¨ 2. è²»ç”¨ä»£è™Ÿèˆ‡ç§‘ç›®å°æ‡‰è¡¨ (è«‹å‹™å¿…è£œé½Šæ‰€æœ‰ 001~033 çš„é …ç›®)
FEE_MAPPING = {
    '001': {'Name': 'å…¶ä»–è²»ç”¨', 'Code': '6135'},
    '002': {'Name': 'è³‡ç”¢è¨­å‚™æ¡è³¼', 'Code': '6137'},
    '003': {'Name': 'é›œé …', 'Code': '612901'},
    '004': {'Name': 'éƒµè³‡', 'Code': '611602'},
    '005': {'Name': 'åŠ æ²¹æ²¹è³‡', 'Code': '6140'},
    '006': {'Name': 'æ–‡å…·ç”¨å“', 'Code': '6113'},
    '007': {'Name': 'å¯„å¿«éé‹è²»', 'Code': '6115'},
    '010': {'Name': 'è¾¦å…¬å®¤æ¸…æ½”è²»', 'Code': '6135'},
    '011': {'Name': 'å„é¡ç§Ÿé‡‘è²»ç”¨', 'Code': '6112'},
    '012': {'Name': 'é›²ç«¯æœå‹™è²»', 'Code': '611604'},
    '013': {'Name': 'ä»£æ‰£ç¨…æ¬¾ç¹³æ¬¾', 'Code': '225202'},
    '014': {'Name': 'ä»£æ‰£è£œå……ä¿è²»ç¹³æ¬¾', 'Code': '225204'},
    '015': {'Name': 'å‹å‹™äººåŠ›è²»ç”¨ç­‰', 'Code': '6133'},
    '016': {'Name': 'æè´ˆç‰©è³‡ç¾é‡‘ç­‰', 'Code': '6122'},
    '017': {'Name': 'é ä»˜çµå¸³å–®', 'Code': '1266'},
    '018': {'Name': 'æš«ä»˜åŸå‰µé‹è²»', 'Code': '2251'},
    '019': {'Name': 'é ä»˜è²»ç”¨-å…¶ä»–', 'Code': '1272'},
    '020': {'Name': 'è¨ˆç¨‹è»Š/äº¤é€šè»Šè³‡', 'Code': '6140'},
    '021': {'Name': 'å…¬å¸ç›¸é—œç¨…æ', 'Code': '6135'},
    '022': {'Name': 'å» å•†è´ˆç¦®/ç”¨é¤', 'Code': '6121'},
    '023': {'Name': 'æ°´é›»ç“¦æ–¯è²»', 'Code': '6119'},
    '024': {'Name': 'é ä»˜è²»ç”¨', 'Code': '1260'},
    '025': {'Name': 'æš«ä»˜æ¬¾', 'Code': '1281'},
    '026': {'Name': 'è·å·¥ç¦åˆ©', 'Code': '611601'},
    '027': {'Name': 'ç”³å ±è–ªè³‡é¡åˆ¥', 'Code': '6111'},
    '028': {'Name': 'æŠ¼é‡‘', 'Code': '1583'},
    '029': {'Name': 'é›»è©±/ç¶²è·¯è²»', 'Code': '611601'},
    '030': {'Name': 'ä¿éšªè²»', 'Code': '6120'},
    '031': {'Name': 'å»£å‘Šç›¸é—œè²»ç”¨', 'Code': '614107'},
    '032': {'Name': 'ä»£ä»˜è²»ç”¨', 'Code': '1282'},
    '033': {'Name': 'è¿”é„‰è£œåŠ©è²»ç”¨', 'Code': '6140'},
}

# 3. å®šç¾©ä¸­æ–‡åˆ†è©å‡½æ•¸
def chinese_segmentation(text):
    """å°‡ä¸­æ–‡æ–‡æœ¬åˆ†è©ï¼Œä»¥ç©ºæ ¼é€£æ¥"""
    if pd.isna(text):
        return ""
    # é€™è£¡å¯ä»¥åŠ å…¥åœç”¨è©è™•ç† (stop words)ï¼Œä½†ç‚ºäº†ç°¡æ½”æš«æ™‚çœç•¥
    return " ".join(jieba.cut(str(text)))

@st.cache_resource # ä½¿ç”¨ Streamlit ç·©å­˜ï¼Œç¢ºä¿æ¨¡å‹åªè¨“ç·´ä¸€æ¬¡
def train_and_prepare_model(file_path):
    """å¾ Excel æ–‡ä»¶è®€å–æ•¸æ“šä¸¦è¨“ç·´æ¨¡å‹"""
    if not os.path.exists(file_path):
        st.error(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è¨“ç·´æ•¸æ“šæ–‡ä»¶: {file_path}ã€‚è«‹ç¢ºä¿æª”æ¡ˆå­˜åœ¨ã€‚")
        return None, None, None, None

    try:
        df = pd.read_excel(file_path)
    except Exception as e:
        st.error(f"éŒ¯èª¤ï¼šè®€å– Excel æ–‡ä»¶å¤±æ•—ã€‚è«‹ç¢ºèªæª”æ¡ˆæ ¼å¼æ˜¯å¦æ­£ç¢ºã€‚{e}")
        return None, None, None, None

    # æ•¸æ“šæ¸…æ´—ï¼šç§»é™¤ç©ºå€¼ä¸¦ç¢ºä¿æ¬„ä½åç¨±æ­£ç¢º
    df = df.dropna(subset=['æ‘˜è¦', 'ç§‘ç›®ç·¨è™Ÿ'])
    df['ç§‘ç›®ç·¨è™Ÿ'] = df['ç§‘ç›®ç·¨è™Ÿ'].astype(str)
    
    Y = df['ç§‘ç›®ç·¨è™Ÿ'] 
    df['æ‘˜è¦_åˆ†è©'] = df['æ‘˜è¦'].apply(chinese_segmentation)
    X = df['æ‘˜è¦_åˆ†è©']

    vectorizer = TfidfVectorizer(max_features=5000)
    X_vectorized = vectorizer.fit_transform(X)

    model = KNeighborsClassifier(n_neighbors=N_NEIGHBORS, metric='cosine') 
    model.fit(X_vectorized, Y)

    # å»ºç«‹åå‘å°æ‡‰è¡¨ (REVERSE_MAPPING)
    REVERSE_MAPPING = {}
    for option_code, details in FEE_MAPPING.items():
        account_code = details['Code']
        if account_code not in REVERSE_MAPPING:
            REVERSE_MAPPING[account_code] = []
        REVERSE_MAPPING[account_code].append(option_code)

    return model, vectorizer, df, REVERSE_MAPPING

# --- æ­¥é©ŸäºŒï¼šé æ¸¬èˆ‡è¼¸å‡º ---

def predict_account_with_support(summary, model, vectorizer, history_df, reverse_mapping):
    """
    é æ¸¬ ç§‘ç›®ç·¨è™Ÿï¼Œç„¶å¾ŒåæŸ¥å°æ‡‰çš„ è²»ç”¨é¡åˆ¥ä»£è™Ÿ å’Œ åç¨±ã€‚
    """
    if not summary.strip():
        return {'Code': 'N/A', 'Name': 'æ‘˜è¦ç‚ºç©º', 'Account': 'N/A'}, []

    seg_summary = chinese_segmentation(summary)
    new_X_vectorized = vectorizer.transform([seg_summary])
    
    # ç²å–è·é›¢æœ€è¿‘çš„ N å€‹é„°å±… (é€™è£¡æ˜¯ ç§‘ç›®ç·¨è™Ÿ)
    distances, indices = model.kneighbors(new_X_vectorized)
    
    # å–å¾—é€™ N å€‹æœ€ç›¸ä¼¼é„°å±…çš„ ç§‘ç›®ç·¨è™Ÿ
    nearest_codes = history_df.iloc[indices[0]]['ç§‘ç›®ç·¨è™Ÿ'].tolist()
    
    # è¨ˆç®— ç§‘ç›®ç·¨è™Ÿ çš„æŠ•ç¥¨æ•¸
    code_counts = Counter(nearest_codes)
    
    # å½™æ•´ Top K æ¨è–¦åˆ—è¡¨
    recommendations = []
    final_option_map = {} 

    for account_code, count in code_counts.most_common():
        # åæŸ¥é€™å€‹ ç§‘ç›®ç·¨è™Ÿ æ‡‰è©²æ¨è–¦å“ªäº› è²»ç”¨é¡åˆ¥ä»£è™Ÿ
        option_codes = reverse_mapping.get(account_code, ['æœªçŸ¥ä»£è™Ÿ'])
        
        # ç”±æ–¼ä¸€å€‹ç§‘ç›®ç·¨è™Ÿå¯èƒ½å°æ‡‰å¤šå€‹è²»ç”¨é¡åˆ¥ï¼Œæˆ‘å€‘å°‡å®ƒå€‘å…¨éƒ¨é¡¯ç¤º
        for option_code in option_codes:
            details = FEE_MAPPING.get(option_code, {'Name': 'æœªçŸ¥åç¨±', 'Code': 'æœªçŸ¥ç·¨è™Ÿ'})
            
            recommendations.append({
                'ä»£è™Ÿ': option_code,
                'åç¨±': details['Name'],
                'ç§‘ç›®ç·¨è™Ÿ': account_code,
                'æ”¯æŒåº¦': f"{count}/{N_NEIGHBORS}",
                'æ”¯æŒæ¯”ä¾‹': f"{(count / N_NEIGHBORS) * 100:.0f}%"
            })
            
            # å°‡ç¬¬ä¸€å€‹æ¨è–¦ä½œç‚ºä¸»è¦çµæœ (åªè¨˜éŒ„ä¸€æ¬¡)
            if not final_option_map:
                final_option_map = {'Code': option_code, 'Name': details['Name'], 'Account': account_code}

    return final_option_map, recommendations

# --- Streamlit ç¶²é ä»‹é¢ä¸»ç¨‹å¼ ---

st.set_page_config(page_title="æœƒè¨ˆè²»ç”¨æ™ºèƒ½åˆ†é¡å°å·¥å…·", layout="centered")
st.title("ğŸ¤– è²»ç”¨ç”³è«‹æ™ºèƒ½åˆ†é¡è¼”åŠ©ç³»çµ±")
st.markdown("---")

# 1. è¨“ç·´æ¨¡å‹ (ä½¿ç”¨ Streamlit ç·©å­˜ï¼Œåªé‹è¡Œä¸€æ¬¡)
model, vectorizer, history_df, reverse_mapping = train_and_prepare_model(DATA_FILE)

if model is not None:
    st.success(f"âœ… æ¨¡å‹åŠ è¼‰å®Œæˆï¼ŒåŸºæ–¼ {len(history_df)} ç­†æ­·å²æ•¸æ“šã€‚")
    st.subheader("ğŸ“ è¼¸å…¥è²»ç”¨æ‘˜è¦")
    
    # 2. å‰µå»ºè¼¸å…¥æ¡†
    user_input = st.text_area("è«‹è¼¸å…¥ç™¼ç¥¨æˆ–è²»ç”¨ç”³è«‹çš„æ‘˜è¦å…§å®¹ï¼š", height=100)

    if st.button("ğŸ” é–‹å§‹é æ¸¬ç§‘ç›®") and user_input:
        with st.spinner('AI æ­£åœ¨è¨ˆç®—æœ€ä½³ç§‘ç›®...'):
            main_option, recommendations = predict_account_with_support(user_input, model, vectorizer, history_df, reverse_mapping)

            # 3. é¡¯ç¤ºä¸»è¦æ¨è–¦çµæœ
            st.markdown("---")
            st.header(f"ğŸ’° ä¸»è¦æ¨è–¦ç§‘ç›® (User Option)")
            
            st.info(f"**ä»£è™Ÿï¼š{main_option['Code']} / åç¨±ï¼š{main_option['Name']}**")
            st.subheader(f"æ‹‹è½‰æœƒè¨ˆç§‘ç›®ç·¨è™Ÿ: `{main_option['Account']}`")
            
            st.markdown("---")
            
            # 4. é¡¯ç¤º Top K è©³ç´°æ¨è–¦
            st.subheader("ğŸ’¡ Top K æ¨è–¦æ˜ç´° (ä¿¡å¿ƒåº¦)")
            
            displayed_accounts = set()
            rec_data = []
            
            for rec in recommendations:
                if rec['ç§‘ç›®ç·¨è™Ÿ'] not in displayed_accounts:
                    rec_data.append({
                        "æ¨è–¦ä»£è™Ÿ": rec['ä»£è™Ÿ'],
                        "ç§‘ç›®åç¨±": rec['åç¨±'],
                        "æœƒè¨ˆç·¨è™Ÿ": rec['ç§‘ç›®ç·¨è™Ÿ'],
                        "æ”¯æŒæ¯”ä¾‹": rec['æ”¯æŒæ¯”ä¾‹'],
                    })
                    displayed_accounts.add(rec['ç§‘ç›®ç·¨è™Ÿ'])
            
            st.dataframe(pd.DataFrame(rec_data), hide_index=True)
            
            st.caption(f"ï¼ˆç³»çµ±æ ¹æ“šæœ€ç›¸ä¼¼çš„ {N_NEIGHBORS} ç­†æ­·å²æ•¸æ“šè¨ˆç®—æ”¯æŒåº¦ï¼‰")

    st.markdown("---")
    st.markdown("##### *è«‹éµå¾ªæ‘˜è¦è¼¸å…¥å„ªåŒ–æŒ‡å—ï¼Œä»¥ç²å¾—æœ€é«˜æº–ç¢ºåº¦ã€‚*")
